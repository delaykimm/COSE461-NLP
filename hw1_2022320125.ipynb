{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OlTaYqZ2rrm"
      },
      "source": [
        "# 5. **Torch를 활용한 자연어처리**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7URa7s_RBcHx"
      },
      "outputs": [],
      "source": [
        "!pip install torchtext==0.14.0\n",
        "!pip install torchdata==0.5.0\n",
        "!pip install torch==1.13.1\n",
        "# 코드 실행 이후 Restart_runtime 해주시면 되겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4lVi253ByX1"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import MNLI\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjNkey2SByZe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터 생성 및 확인\n",
        "dataset = list(MNLI(split='train'))\n",
        "train_data, val_data = train_test_split(dataset, test_size=0.1, random_state=42)\n",
        "\n",
        "test_data = list(MNLI(split='dev_matched'))\n",
        "\n",
        "# 0: entailment, 1: neutral, 2: contradiction\n",
        "tmp = train_data[0]\n",
        "print(f\"label:      {tmp[0]}\")\n",
        "print(f\"premise:    {tmp[1]}\")\n",
        "print(f\"hypothesis: {tmp[2]}\")\n",
        "\n",
        "# premise, hypothesis를 입력으로 해서 label을 맞추는 작업"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT30IZp_NCrs"
      },
      "outputs": [],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8s3rJwJBybR"
      },
      "outputs": [],
      "source": [
        "# 토크나이저\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "train_iter = iter(MNLI(split='train'))\n",
        "test_iter = iter(MNLI(split='dev_matched'))\n",
        "\n",
        "# 각 텍스트 문서에 대해서 토크나이징 진행\n",
        "def yield_tokens(data_iter):\n",
        "    for _, premise, hypothesis in data_iter:\n",
        "        yield tokenizer(premise)\n",
        "        yield tokenizer(hypothesis)\n",
        "\n",
        "# 토크 나이징 한 리스트에서 어휘 사전을 구축\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\", \" <sep> \"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "vocab_size = len(vocab)\n",
        "print(f\"vocab_size: {vocab_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv-B5wc-FbfW"
      },
      "outputs": [],
      "source": [
        "# vocab의 역할: 텍스트를 정수입력 형태로 변환\n",
        "vocab(['here', 'is', 'an', 'example'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGUVwihEJv8D"
      },
      "source": [
        "### **모델 정의하기 (예시)**\n",
        "모델은 `nn.EmbeddingBag` 레이어와 분류(classification) 목적을 위한 선형 레이어로 구성됩니다.\n",
        "\n",
        "기본 모드가 “평균(mean)”인 nn.EmbeddingBag 은 임베딩들의 “가방(bag)”의 평균 값을 계산합니다. 이때 텍스트(text) 항목들은 각기 그 길이가 다를 수 있지만, nn.EmbeddingBag 모듈은 *텍스트의 길이를 오프셋(offset)으로 저장하고 있으므로 패딩(padding)이 필요하지는 않습니다.*\n",
        "\n",
        "\n",
        "![모델](https://tutorials.pytorch.kr/_images/text_sentiment_ngrams_model.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bDZ3vGsFbg7"
      },
      "outputs": [],
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class = 3):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim)  # fully connected\n",
        "        self.fc2 = nn.Linear(embed_dim, num_class)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.bias.data.zero_()\n",
        "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc2.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        embedded = self.fc1(embedded)\n",
        "        embedded = self.relu(embedded)\n",
        "        embedded = self.fc2(embedded)\n",
        "        return embedded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBbV7N_JDkiU"
      },
      "source": [
        "### Validation 함수 정의\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14SYjeeQ8V_u"
      },
      "outputs": [],
      "source": [
        "def validate(model, criterion, valid_loader):\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "    valid_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # 그래디언트 계산 비활성화\n",
        "        for inputs, labels in valid_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # 검증 데이터셋에 대한 손실과 정확도 계산\n",
        "    valid_loss /= len(valid_loader)\n",
        "    valid_accuracy = correct / total\n",
        "\n",
        "    return valid_loss, valid_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt1SH2-e8CK7"
      },
      "source": [
        "### 데이터셋 정의하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlUegeB18Fbh"
      },
      "outputs": [],
      "source": [
        "class CustomTextDataset(Dataset):\n",
        "    def __init__(self, data_list, tokenizer, vocab):\n",
        "        self.data_list = data_list\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, premise, hypothesis = self.data_list[idx]\n",
        "        inputs = premise + ' ' + hypothesis\n",
        "        inputs = self.tokenizer(inputs)\n",
        "        inputs = [self.vocab[token] for token in inputs]\n",
        "        inputs = torch.tensor(inputs, dtype=torch.long)\n",
        "        return inputs, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        inputs, labels = zip(*batch)\n",
        "        # 패딩된 시퀀스 생성\n",
        "        inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "        labels_tensor = torch.stack(labels)\n",
        "        return inputs_padded, labels_tensor\n",
        "\n",
        "train_dataset = CustomTextDataset(train_data, tokenizer, vocab)\n",
        "val_dataset = CustomTextDataset(val_data, tokenizer, vocab)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=CustomTextDataset.collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=CustomTextDataset.collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqoKWjvJSOi1"
      },
      "source": [
        "### **학습 정의**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICgqI-FH8aIL"
      },
      "outputs": [],
      "source": [
        "emsize = 64\n",
        "from torch.optim import SparseAdam\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저, 스케줄러 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class=3).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.3)\n",
        "# SparseAdam, AdaGrad, RMSProp, Adadelta\n",
        "#optimizer = SparseAdam(model.parameters(), lr=0.001)\n",
        "\n",
        "#scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, threshold= 0.02 , patience = 5, min_lr=1e-4, verbose=True)\n",
        "#scheduler = StepLR(optimizer, step_size=5, gamma=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOrYtBm2QGH-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# gradient tensor 값 분포를 확인하기 위한 시각화\n",
        "def visualize_gradient_distribution(grad_tensor):\n",
        "    # 그래디언트 텐서를 1차원 배열로 변환하여 히스토그램 작성.\n",
        "    grad_dense = grad_tensor.to_dense()\n",
        "    grad_values = grad_tensor.detach().cpu().numpy().flatten()\n",
        "\n",
        "    # 히스토그램 작성\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(grad_values, bins=50, color='skyblue', alpha=0.7)\n",
        "    plt.title('Gradient Distribution')\n",
        "    plt.xlabel('Gradient Values')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpJXec-UJrwa"
      },
      "outputs": [],
      "source": [
        "#scheduler = StepLR(optimizer, step_size=5, gamma=0.3)\n",
        "max_epochs = 20\n",
        "for epoch in range(max_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if (i + 1) % 1000 == 0 or (i + 1) == len(train_loader):\n",
        "            print(f'Epoch {epoch+1}/{max_epochs}, Batch {i+1}, Loss: {running_loss / min(1000, i+1):.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "    # 검증\n",
        "    valid_loss, valid_accuracy = validate(model, criterion, val_loader)\n",
        "    print(f'Epoch [{epoch+1}/{max_epochs}], Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_accuracy:.4f}')\n",
        "\n",
        "    # 학습률 체크\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Current learning rate: {current_lr}\")\n",
        "    if current_lr < 1e-5:\n",
        "        print(\"Learning rate is below 1e-7. Stopping training.\")\n",
        "        break\n",
        "\n",
        "    #scheduler.step(valid_accuracy)  # 에포크 마지막에서 업데이트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTstDaM9SRZ9"
      },
      "source": [
        "### **학습된 모델 평가**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlZcslYBHWwy"
      },
      "outputs": [],
      "source": [
        "total_acc, total_count = 0, 0\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # gpu가속을 위함\n",
        "model = model.to(device)\n",
        "\n",
        "for i, data in enumerate(test_data):\n",
        "    # 데이터 호출\n",
        "    label = data[0]\n",
        "    premise = data[1]\n",
        "    hypothesis = data[2]\n",
        "\n",
        "    # Forward pass\n",
        "    inputs = premise + ' ' + hypothesis  # premise와 hypothesis를 모두 고려하기 위한 입력 구성\n",
        "    inputs = vocab(tokenizer(inputs))  # 텍스트 형태의 입력을 모델이 이해 가능한 형태로 변환 (정수형)\n",
        "    inputs = torch.as_tensor(inputs, dtype=torch.int32).unsqueeze(0)  # 모델이 받을 수 있는 데이터 형태로 변환\n",
        "    label = torch.as_tensor(label, dtype=torch.long).unsqueeze(0) # 모델이 받을 수 있는 데이터 형태로 변환\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    predicted_label = model(inputs)\n",
        "    predicted_label = predicted_label.detach().cpu()\n",
        "\n",
        "    total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "    total_count += label.size(0)\n",
        "\n",
        "    if (i+1) % 1000 == 0:\n",
        "        print(f'평가 진행중.. [{i+1}/{len(test_data)}]')\n",
        "\n",
        "print(f\"학습된 모델의 최종 정확도: {format(total_acc/total_count * 100, '.3f')} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSO5f3r1Ur6W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRQMf_oCUr9Y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
